{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 1.Python is a pretty versatile language. \n",
    " * for quick calculations.\n",
    " * to develop a database-driven website.\n",
    " * to clean and analyze the results of the latest satisfaction survey.</p>\n",
    "<p>2.Python is perfectly suited to do basic calculations \n",
    " * Exponentiation: **\n",
    " * Modulo: %</p>\n",
    "<p>To find out the type of a value or a variable that refers to that value, you can use the *type()* function.\n",
    "*str()*, to convert a value into a string.Similar functions such as *int(), float() and bool()* will help you convert Python values into any type.</p>\n",
    "#### Comment:\n",
    "<p>To add comments to your Python script, you can use the # tag\n",
    "The ; sign is used to place commands on the same line. The following two code chunks are equivalent:\n",
    "\n",
    "       #Same line\n",
    "        command1; command2\n",
    "\n",
    "       #Separate lines\n",
    "        command1\n",
    "        command2\n",
    "</p>\n",
    "<p>The general recipe for calling functions and saving the result to a variable is thus:\n",
    "       *output = function_name(input)*\n",
    "       \n",
    "To ask for information about a function with another function: \n",
    "    *help()*, can also use '?' \n",
    "</p>    \n",
    "## LIST \n",
    "<p>A list can contain any Python type. Although it's not really common, a list can also contain a mix of Python types including strings, floats, booleans, etc.\n",
    "To slice your list, which means selecting multiple elements from your list. Use the following syntax:\n",
    "          * my_list[start:end]\n",
    "The start index will be included, while the end index is not.\n",
    "To remove elements from your list. You can do this with the del statement.\n",
    "To do a more explicit copy , by using [:].</p>\n",
    "#### List Methods:\n",
    "<p>* *index()*, to get the index of the first element of a list that matches its input and\n",
    "* *count()*, to get the number of times an element appears in a list.\n",
    "* *append()*, that adds an element to the list it is called on,\n",
    "* *remove()*, that removes the first element of a list that matches the input, and\n",
    "* *reverse()*, that reverses the order of the elements in the list it is called on.</p>\n",
    "<p> General imports, like import math, make all functionality from the math package available to you. However, if you decide to only use a specific part of a package, you can always make your import more selective:\n",
    "                                 * from math import pi                                  \n",
    "There are several ways to import packages and modules into Python. Depending on the import call, you'll have to use different Python code.Suppose you want to use the function *inv()*, which is in the linalg subpackage of the scipy package.</p>\n",
    "## NumPy\n",
    "<p>Numpy, a powerful package to do data science.numpy is great for doing vector arithmetic.\n",
    "Numpy arrays cannot contain elements with different types. If you try to build such a list, some of the elements' types are changed to end up with a homogeneous list. This is known as type coercion.Second, the typical arithmetic operators, such as +, -, * and / have a different meaning for regular Python lists and numpy arrays.\n",
    "* *np.array()* to create a 2D numpy array.\n",
    "The indexes before the comma refer to the rows, while those after the comma refer to the columns. The : is for slicing.\n",
    "\n",
    "\n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example:\n",
    "<p>You've contacted FIFA for some data and they handed you two lists. The lists are the following:\n",
    "\n",
    "positions = ['GK', 'M', 'A', 'D', ...]\n",
    "heights = [191, 184, 185, 180, ...]\n",
    "Each element in the lists corresponds to a player. The first list, positions, contains strings representing each player's position. The possible positions are: 'GK' (goalkeeper), 'M' (midfield), 'A' (attack) and 'D' (defense). The second list, heights, contains integers representing the height of the player in cm. The first player in the lists is a goalkeeper and is pretty tall (191 cm).\n",
    "\n",
    "You're fairly confident that the median height of goalkeepers is higher than that of other players on the soccer field. Some of your friends don't believe you, so you are determined to show them using the data you received from FIFA and your newly acquired Python skills.\n",
    "\n",
    "<p>Convert heights and positions, which are regular lists, to numpy arrays. Call them np_heights and np_positions.\n",
    "Extract all the heights of the goalkeepers. You can use a little trick here: use np_positions == 'GK' as an index for np_heights. Assign the result to gk_heights.\n",
    "Extract all the heights of all the other players. This time use np_positions != 'GK' as an index for np_heights. Assign the result to other_heights.\n",
    "Print out the median height of the goalkeepers using np.median(). Replace None with the correct code.\n",
    "Do the same for the other players. Print out their median height. Replace None with the correct code.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# heights and positions are available as lists\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Convert positions and heights to numpy arrays: np_positions, np_heights\n",
    "np_heights = np.array(heights)\n",
    "np_positions = np.array(positions)\n",
    "\n",
    "\n",
    "# Heights of the goalkeepers: gk_heights\n",
    "gk_heights = np_heights[np_positions == 'GK']\n",
    "\n",
    "# Heights of the other players: other_heights\n",
    "other_heights = np_heights[np_positions != 'GK']\n",
    "\n",
    "# Print out the median height of goalkeepers. Replace 'None'\n",
    "print(\"Median height of goalkeepers: \" + str(np.median(gk_heights)))\n",
    "print(\"Median height of other players: \" + str(np.median(other_heights)))\n",
    "# Print out the median height of other players. Replace 'None'\n",
    "print(\"Median height of other players: \" + str(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib\n",
    "<p>The most basic plot is the line plot. \n",
    "* import matplotlib.pyplot as plt\n",
    "  *plt.plot(x,y)*\n",
    "  plt.show()</p>\n",
    "pyplot is a sub-package of matplotlib, hence the dot.</p>  \n",
    "<p> To build a scatter plot\n",
    "* import matplotlib.pyplot as plt\n",
    "  *plt.scatter(x,y)*\n",
    "  plt.show()\n",
    "<p> To put the x-axis on a logarithmic scale\n",
    "    *plt.xscale('log')* </p> \n",
    "<p> *plt.hist()* to create a histogram </p>\n",
    "<p> clean up plot- *plt.clf()* </p>\n",
    "<p> To add axis and title labels \n",
    "    xlabel(), ylabel() and title()</p>\n",
    "<p> To control the y-ticks by specifying two arguments:\n",
    "            plt.yticks([0,1,2], [\"one\",\"two\",\"three\"])\n",
    "    In this example, the ticks corresponding to the numbers 0, 1 and 2 will be replaced by one, two and three,    respectively.</p>\n",
    "## Dictionary\n",
    "<p> for creating a dictionary:\n",
    "   my_dict = {\n",
    "   \"key1\":\"value1\",\n",
    "   \"key2\":\"value2\",\n",
    "    }\n",
    "To check out which keys are in by calling the *keys()* method.   \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary Manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Add the key 'italy' with the value 'rome' to europe.\n",
    "To assert that 'italy' is now a key in europe, print out 'italy' in europe.\n",
    "Add another key:value pair to europe: 'poland' is the key, 'warsaw' is the corresponding value.\n",
    "Print out europe.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definition of dictionary\n",
    "europe = {'spain':'madrid', 'france':'paris', 'germany':'berlin', 'norway':'oslo' }\n",
    "\n",
    "# Add italy to europe\n",
    "europe['italy'] = 'rome'\n",
    "\n",
    "# Print out italy in europe\n",
    "print('italy' in europe)\n",
    "\n",
    "# Add poland to europe\n",
    "europe['poland'] = 'warsaw'\n",
    "\n",
    "# Print europe\n",
    "print(europe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The capital of Germany is not 'bonn'; it's 'berlin'. Update its value.\n",
    "Australia is not in Europe, Austria is! Remove the key 'australia' from europe.\n",
    "Print out europe to see if your cleaning work paid off.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definition of dictionary\n",
    "europe = {'spain':'madrid', 'france':'paris', 'germany':'bonn',\n",
    "          'norway':'oslo', 'italy':'rome', 'poland':'warsaw',\n",
    "          'australia':'vienna' }\n",
    "\n",
    "# Update capital of germany\n",
    "europe[\"germany\"] = \"berlin\"\n",
    "\n",
    "# Remove australia\n",
    "del europe[\"australia\"]\n",
    "\n",
    "# Print europe\n",
    "print (europe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Use chained square brackets to select and print out the capital of France.\n",
    "Create a dictionary, named data, with the keys 'capital' and 'population'. Set them to 'rome' and 59.83, respectively.\n",
    "Add a new key-value pair to europe; the key is 'italy' and the value is data, the dictionary you just built.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary of dictionaries\n",
    "europe = { 'spain': { 'capital':'madrid', 'population':46.77 },\n",
    "           'france': { 'capital':'paris', 'population':66.03 },\n",
    "           'germany': { 'capital':'berlin', 'population':80.62 },\n",
    "           'norway': { 'capital':'oslo', 'population':5.084 } }\n",
    "\n",
    "\n",
    "# Print out the capital of France\n",
    "print(europe['france']['capital'])\n",
    "\n",
    "# Create sub-dictionary data\n",
    "data = {\n",
    "    'capital':'rome', 'population':59.83\n",
    "}\n",
    "europe[\"italy\"] = data\n",
    "print(europe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PANDAS\n",
    "<p>Pandas is an open source library, providing high-performance, easy-to-use data structures and data analysis tools for Python. \n",
    "The DataFrame is one of Pandas' most important data structures. It's basically a way to store tabular data where you can label the rows and the columns. One way to build a DataFrame is from a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### example\n",
    "Import pandas as pd.\n",
    "Use the pre-defined lists to create a dictionary called my_dict. There should be three key value pairs:\n",
    "key 'country' and value names.\n",
    "key 'drives_right' and value dr.\n",
    "key 'cars_per_cap' and value cpc.\n",
    "Use pd.DataFrame() to turn your dict into a DataFrame called cars.\n",
    "Print out cars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-defined lists\n",
    "names = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']\n",
    "dr =  [True, False, False, False, True, True, True]\n",
    "cpc = [809, 731, 588, 18, 200, 70, 45]\n",
    "\n",
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Create dictionary my_dict with three key:value pairs: my_dict\n",
    "my_dict = {\n",
    "    \"country\": ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt'],\n",
    "    \"drives_right\":[True, False, False, False, True, True, True],\n",
    "    \"cars_per_cap\":[809, 731, 588, 18, 200, 70, 45]\n",
    "    \n",
    "}\n",
    "\n",
    "# Build a DataFrame cars from my_dict: cars\n",
    "cars = pd.DataFrame(my_dict)\n",
    "\n",
    "# Print cars\n",
    "print(cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Build cars DataFrame\n",
    "names = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']\n",
    "dr =  [True, False, False, False, True, True, True]\n",
    "cpc = [809, 731, 588, 18, 200, 70, 45]\n",
    "dict = { 'country':names, 'drives_right':dr, 'cars_per_cap':cpc }\n",
    "cars = pd.DataFrame(dict)\n",
    "print(cars)\n",
    "\n",
    "# Definition of row_labels\n",
    "row_labels = ['US', 'AUS', 'JAP', 'IN', 'RU', 'MOR', 'EG']\n",
    "\n",
    "# Specify row labels of cars\n",
    "cars.index = row_labels\n",
    "print(cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The data is typically available as files with a regular structure. One of those file types is the CSV file, which is short for \"comma-separated values\".\n",
    "To import CSV data into Python as a Pandas DataFrame you can use *read_csv()*.\n",
    "* Use pd.read_csv() to import data as a DataFrame\n",
    "To index and select Pandas DataFrames,the simplest but not the most powerful way, is to use square brackets.\n",
    "   The single bracket version gives a Pandas Series, the double bracket version gives a Pandas DataFrame.\n",
    "\n",
    "Square brackets can do more than just selecting columns. You can also use them to get rows, or observations, from a DataFrame. </p>\n",
    "\n",
    "###### ex.\n",
    "<p> Use single square brackets to print out the country column of cars as a Pandas Series.\n",
    "Use double square brackets to print out the country column of cars as a Pandas DataFrame.\n",
    "Use double square brackets to print out a DataFrame with both the country and drives_right columns of cars, in this ord </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Print out country column as Pandas Series\n",
    "print (cars[\"country\"])\n",
    "\n",
    "# Print out country column as Pandas DataFrame\n",
    "print (cars[[\"country\"]])\n",
    "\n",
    "# Print out DataFrame with country and drives_right columns\n",
    "print (cars[[\"country\",\"drives_right\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ex.\n",
    "Select the first 3 observations from cars and print them out.\n",
    "Select the fourth, fifth and sixth observation, corresponding to row indexes 3, 4 and 5, and print them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "\n",
    "# Print out first 3 observations\n",
    "print(cars[0:3])\n",
    "\n",
    "# Print out fourth, fifth and sixth observation\n",
    "print(cars[3:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loc and iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>With *loc* and *iloc* you can do practically any data selection operation on DataFrames you can think of. \n",
    "* loc is label-based, which means that you have to specify rows and columns based on their row and column labels. \n",
    "* iloc is integer index based, so you have to specify rows and columns by their integer index like you did in the previous exercise.</p>\n",
    "\n",
    "It's also possible to select only columns with loc and iloc. In both cases, you simply put a slice going from beginning to end in front of the comma:\n",
    "\n",
    "cars.loc[:, 'country']\n",
    "cars.iloc[:, 1]\n",
    "\n",
    "cars.loc[:, ['country','drives_right']]\n",
    "cars.iloc[:, [1, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ex.\n",
    "Use loc or iloc to select the observation corresponding to Japan as a Series. The label of this row is JAP, the index is 2. Make sure to print the resulting Series.\n",
    "Use loc or iloc to select the observations for Australia and Egypt as a DataFrame. You can find out about the labels/indexes of these rows by inspecting cars in the IPython Shell. Make sure to print the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Print out observation for Japan\n",
    "print(cars.loc['JAP'])\n",
    "print (cars.iloc[2])\n",
    "print (cars)\n",
    "# Print out observations for Australia and Egypt\n",
    "print (cars.loc[[\"AUS\",\"EG\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ex.\n",
    "Print out the drives_right value of the row corresponding to Morocco (its row label is MOR)\n",
    "Print out a sub-DataFrame, containing the observations for Russia and Morocco and the columns country and drives_right.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Print out drives_right value of Morocco\n",
    "print (cars.loc[\"MOR\",\"drives_right\"])\n",
    "\n",
    "# Print sub-DataFrame\n",
    "print (cars.loc[[\"RU\",\"MOR\"],[\"country\",\"drives_right\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic, Control Flow and Filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if two Python values, or variables, are equal you can use ==. To check for inequality, you need !=\n",
    "The less than and greater than signs---- < and >. \n",
    "We can combine them with an equals sign: <= and >= , <= is valid syntax, but =< is not.\n",
    "##### Boolean Operators\n",
    "A boolean is either 1 or 0, True or False. With boolean operators such as and, or and not, you can combine these booleans to perform more advanced queries on your data.\n",
    "###### ex.\n",
    "Write Python expressions, wrapped in a print() function, to check whether:\n",
    "my_kitchen is bigger than 10 and smaller than 18.\n",
    "my_kitchen is smaller than 14 or bigger than 17.\n",
    "double the area of my_kitchen is smaller than triple the area of your_kitchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define variables\n",
    "my_kitchen = 18.0\n",
    "your_kitchen = 14.0\n",
    "\n",
    "# my_kitchen bigger than 10 and smaller than 18?\n",
    "print (my_kitchen>10 and my_kitchen<18)\n",
    "\n",
    "# my_kitchen smaller than 14 or bigger than 17?\n",
    "print (my_kitchen < 14 or my_kitchen > 17)\n",
    "\n",
    "# Double my_kitchen smaller than triple your_kitchen?\n",
    "print (2*my_kitchen < 3*your_kitchen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operational operators like < and >= worked with Numpy arrays out of the box. Unfortunately, this is not true for the boolean operators and, or, and not.\n",
    "\n",
    "<p>To use these operators with Numpy, you will need \n",
    "* np.logical_and(), \n",
    "* np.logical_or() and \n",
    "* np.logical_not(). </p>\n",
    "\n",
    "Here's an example on the my_house and your_house arrays from before to give you an idea:\n",
    "      np.logical_and(your_house > 13, \n",
    "      your_house < 15) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples:\n",
    "#### 1.\n",
    "Extract the drives_right column as a Pandas Series and store it as dr.\n",
    "Use dr, a boolean Series, to subset the cars DataFrame. Store the resulting selection in sel.\n",
    "Print sel, and assert that drives_right is True for all observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Extract drives_right column as Series: dr\n",
    "\n",
    "dr = cars[\"drives_right\"]\n",
    "# Use dr to subset cars: sel\n",
    "sel = cars[dr]\n",
    "\n",
    "# Print sel\n",
    "print (sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Convert the code to a one-liner that calculates the variable sel as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Convert code to a one-liner\n",
    "#dr = cars['drives_right']\n",
    "sel = cars[cars['drives_right']]\n",
    "\n",
    "# Print sel\n",
    "print(sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. \n",
    "Select the cars_per_cap column from cars as a Pandas Series and store it as cpc.\n",
    "Use cpc in combination with a comparison operator and 500. You want to end up with a boolean Series that's True if the corresponding country has a cars_per_cap of more than 500 and False otherwise. Store this boolean Series as many_cars.\n",
    "Use many_cars to subset cars, similar to what you did before. Store the result as car_maniac.\n",
    "Print out car_maniac to see if you got it right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Create car_maniac: observations that have a cars_per_cap over 500\n",
    "\n",
    "cpc = cars[\"cars_per_cap\"]\n",
    "many_cars = cpc > 500 \n",
    "car_maniac = cars[many_cars]\n",
    "# Print car_maniac\n",
    "print (car_maniac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take this example that selects the observations that have a cars_per_cap between 10 and 80. Try out these lines of code step by step to see what's happening.\n",
    "\n",
    "cpc = cars['cars_per_cap']\n",
    "between = np.logical_and(cpc > 10, cpc < 80)\n",
    "medium = cars[between] \n",
    "\n",
    "Use the code sample above to create a DataFrame medium, that includes all the observations of cars that have a cars_per_cap between 100 and 500.\n",
    "Print out medium.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Import numpy, you'll need this\n",
    "import numpy as np\n",
    "\n",
    "# Create medium: observations with cars_per_cap between 100 and 500\n",
    "cpc = cars['cars_per_cap']\n",
    "between = np.logical_and(cpc > 100, cpc < 500)\n",
    "medium = cars[between]\n",
    "print(medium)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loops\n",
    "###### ex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correcting...\n",
      "7\n",
      "correcting...\n",
      "6\n",
      "correcting...\n",
      "5\n",
      "correcting...\n",
      "4\n",
      "correcting...\n",
      "3\n",
      "correcting...\n",
      "2\n",
      "correcting...\n",
      "1\n",
      "correcting...\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Initialize offset\n",
    "offset = 8\n",
    "\n",
    "# Code the while loop\n",
    "while offset != 0 :\n",
    "    print(\"correcting...\")\n",
    "    offset = offset-1\n",
    "    print (offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correcting...\n",
      "-5\n",
      "correcting...\n",
      "-4\n",
      "correcting...\n",
      "-3\n",
      "correcting...\n",
      "-2\n",
      "correcting...\n",
      "-1\n",
      "correcting...\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Initialize offset\n",
    "offset = -6\n",
    "\n",
    "# Code the while loop\n",
    "while offset != 0 :\n",
    "    print(\"correcting...\")\n",
    "    if offset > 0:\n",
    "        offset= offset-1\n",
    "    else:\n",
    "        offset = offset+1\n",
    "        \n",
    "    print(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.73\n",
      "1.68\n",
      "1.71\n",
      "1.89\n"
     ]
    }
   ],
   "source": [
    "# Loop over a list\n",
    "fam = [1.73, 1.68, 1.71, 1.89]\n",
    "for height in fam : \n",
    "    print(height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a for loop to iterate over a list only gives you access to every list element in each run, one after the other. If you also want to access the index information, so where the list element you're iterating over is located, you can use enumerate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room 0: 11.25\n",
      "room 1: 18.0\n",
      "room 2: 20.0\n",
      "room 3: 10.75\n",
      "room 4: 9.5\n"
     ]
    }
   ],
   "source": [
    "# areas list\n",
    "areas = [11.25, 18.0, 20.0, 10.75, 9.50]\n",
    "\n",
    "# Change for loop to use enumerate()\n",
    "for index,a in enumerate(areas) :\n",
    "    print(\"room \" + str(index) + \": \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hallway is 11.25 sqm\n",
      "the kitchen is 18.0 sqm\n",
      "the living room is 20.0 sqm\n",
      "the bedroom is 10.75 sqm\n",
      "the bathroom is 9.5 sqm\n"
     ]
    }
   ],
   "source": [
    "# house list of lists\n",
    "house = [[\"hallway\", 11.25], \n",
    "         [\"kitchen\", 18.0], \n",
    "         [\"living room\", 20.0], \n",
    "         [\"bedroom\", 10.75], \n",
    "         [\"bathroom\", 9.50]]\n",
    "         \n",
    "# Build a for loop from scratch\n",
    "for x in house:\n",
    "    print(\"the \" + str(x[0]) + \" is \" + str(x[1]) + \" sqm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the capital of spain is madrid\n",
      "the capital of france is paris\n",
      "the capital of germany is berlin\n",
      "the capital of norway is oslo\n",
      "the capital of italy is rome\n",
      "the capital of poland is warsaw\n",
      "the capital of austria is vienna\n"
     ]
    }
   ],
   "source": [
    "# Loop over dictionary\n",
    "# Definition of dictionary\n",
    "europe = {'spain':'madrid', 'france':'paris', 'germany':'berlin',\n",
    "          'norway':'oslo', 'italy':'rome', 'poland':'warsaw', 'austria':'vienna' }\n",
    "          \n",
    "# Iterate over europe\n",
    "for key,value in europe.items():\n",
    "    print(\"the capital of \" + key + \" is \"+ value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over Numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a 1D Numpy array -  for x in my_array :\n",
    "    ...\n",
    "With a 2D Numpy array -  for x in np.nditer(my_array) :\n",
    "    ...   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np_height' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2b4707b2ad80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# For loop over np_height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp_height\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m\" inches \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np_height' is not defined"
     ]
    }
   ],
   "source": [
    "# Import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "# For loop over np_height\n",
    "for x in np_height:\n",
    "    print( str(x) +  \" inches \")\n",
    "\n",
    "# For loop over np_baseball\n",
    "for x in np.nditer(np_baseball) :\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over DataFrame \n",
    "Iterating over a Pandas DataFrame is typically done with the iterrows() method. Used in a for loop, every observation is iterated over and on every iteration the row label and actual row contents are available:\n",
    "\n",
    "   for lab, row in brics.iterrows() :\n",
    "    ...<br>\n",
    "The row data that's generated by iterrows() on every run is a Pandas Series.you can easily select variables from the Pandas Series using square brackets:\n",
    "    for lab, row in brics.iterrows() :\n",
    "    print(row['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Iterate over rows of cars\n",
    "for lab, row in cars.iterrows() :\n",
    "    print(lab)\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Code for loop that adds COUNTRY column\n",
    "for lab, row in cars.iterrows() :\n",
    "    cars.loc[lab, \"COUNTRY\"] = str(row[\"country\"]).upper()\n",
    "\n",
    "\n",
    "# Print cars\n",
    "print(cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using iterrows() to iterate over every observation of a Pandas DataFrame is easy to understand, but not very efficient. On every iteration, you're creating a new Pandas Series.\n",
    "If you want to add a column to a DataFrame by calling a function on another column, the iterrows() method in combination with a for loop is not the preferred way to go. Instead, you'll want to use apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Use .apply(str.upper)\n",
    "cars[\"COUNTRY\"] = cars[\"country\"].apply(str.upper)\n",
    "print (cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example : Hacker statistics\n",
    "To calculate your chances of winning a bet.\n",
    "\n",
    "All the functionality you need is contained in the random package, a sub-package of numpy. In this exercise, you'll be using two functions from this package:\n",
    "\n",
    "seed(): sets the random seed, so that your results are the reproducible between simulations. As an argument, it takes an integer of your choosing. If you call the function, no output will be generated.\n",
    "rand(): if you don't specify any arguments, it generates a random float between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "# Set the seed\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generate and print random float\n",
    "print(np.random.rand())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  randint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import numpy and set seed\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "# Use randint() to simulate a dice\n",
    "print(np.random.randint(1, 7))\n",
    "\n",
    "# Use randint() again\n",
    "print(np.random.randint(1, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roll the dice. Use randint() to create the variable dice.\n",
    "Finish the if-elif-else construct by replacing ___:\n",
    "If dice is 1 or 2, you go one step down.\n",
    "if dice is 3, 4 or 5, you go one step up.\n",
    "Else, you throw the dice again. The number of eyes is the number of steps you go up.\n",
    "Print out dice and step. Given the value of dice, was step updated correctly?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import numpy and set seed\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "# Starting step\n",
    "step = 50\n",
    "\n",
    "# Roll the dice\n",
    "dice = np.random.randint(1,7)\n",
    "\n",
    "# Finish the control construct\n",
    "if dice <= 2 :\n",
    "    step = step - 1\n",
    "elif dice <= 5:\n",
    "    step = step+1\n",
    "else :\n",
    "    step = step + np.random.randint(1,7)\n",
    "# Print out dice and step\n",
    "print(dice)\n",
    "print(step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list random_walk that contains the first step, which is the integer 0.\n",
    "Finish the for loop:\n",
    "The loop should run 100 times.\n",
    "On each iteration, set step equal to the last element in the random_walk list. You can use the index -1 for this.\n",
    "Next, let the if-elif-else construct update step for you.\n",
    "The code that appends step to random_walk is already coded.\n",
    "Print out random_walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import numpy and set seed\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "# Initialize random_walk\n",
    "random_walk = [0]\n",
    "\n",
    "# Complete the ___\n",
    "for x in range(100) :\n",
    "    # Set step: last element in random_walk\n",
    "    step = random_walk[-1]\n",
    "\n",
    "    # Roll the dice\n",
    "    dice = np.random.randint(1,7)\n",
    "\n",
    "    # Determine next step\n",
    "    if dice <= 2:\n",
    "        step = step - 1\n",
    "    elif dice <= 5:\n",
    "        step = step + 1\n",
    "    else:\n",
    "        step = step + np.random.randint(1,7)\n",
    "\n",
    "    # append next_step to random_walk\n",
    "    random_walk.append(step)\n",
    "\n",
    "# Print random_walk\n",
    "print(random_walk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use max() in a similar way to make sure that step doesn't go below zero if dice <= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import numpy and set seed\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "# Initialize random_walk\n",
    "random_walk = [0]\n",
    "\n",
    "for x in range(100) :\n",
    "    step = random_walk[-1]\n",
    "    dice = np.random.randint(1,7)\n",
    "\n",
    "    if dice <= 2:\n",
    "        # Replace below: use max to make sure step can't go below 0\n",
    "        step = max(0,step - 1)\n",
    "        \n",
    "    elif dice <= 5:\n",
    "        step = step + 1\n",
    "    else:\n",
    "        step = step + np.random.randint(1,7)\n",
    "\n",
    "    random_walk.append(step)\n",
    "\n",
    "print(random_walk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the walk\n",
    "Let's visualize this random walk! Remember how you could use matplotlib to build a line plot?\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "The first list you pass is mapped onto the x axis and the second list is mapped onto the y axis.\n",
    "\n",
    "If you pass only one argument, Python will know what to do and will use the index of the list to map onto the x axis, and the values in the list onto the y axis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "random_walk = [0]\n",
    "\n",
    "for x in range(100) :\n",
    "    step = random_walk[-1]\n",
    "    dice = np.random.randint(1,7)\n",
    "\n",
    "    if dice <= 2:\n",
    "        step = max(0, step - 1)\n",
    "    elif dice <= 5:\n",
    "        step = step + 1\n",
    "    else:\n",
    "        step = step + np.random.randint(1,7)\n",
    "\n",
    "    random_walk.append(step)\n",
    "\n",
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot random_walk\n",
    "plt.plot(random_walk)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea about how big your chances are of reaching 60 steps, you can repeatedly simulate the random walk and collect the results. \n",
    "\n",
    "Initialize all_walks to an empty list.\n",
    "Fill in the specification of the for loop so that the random walk is simulated 10 times.\n",
    "After the random_walk array is entirely populated, append the array to the all_walks list.\n",
    "Finally, after the top-level for loop, print out all_walks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "# Initialize all_walks\n",
    "all_walks = []\n",
    "\n",
    "# Simulate random walk 10 times\n",
    "for i in range(10) :\n",
    "\n",
    "    # Code from before\n",
    "    random_walk = [0]\n",
    "    for x in range(100) :\n",
    "        step = random_walk[-1]\n",
    "        dice = np.random.randint(1,7)\n",
    "\n",
    "        if dice <= 2:\n",
    "            step = max(0, step - 1)\n",
    "        elif dice <= 5:\n",
    "            step = step + 1\n",
    "        else:\n",
    "            step = step + np.random.randint(1,7)\n",
    "        random_walk.append(step)\n",
    "\n",
    "    # Append random_walk to all_walks\n",
    "    all_walks.append(random_walk)\n",
    "\n",
    "# Print all_walks\n",
    "print (all_walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "all_walks = []\n",
    "for i in range(10) :\n",
    "    random_walk = [0]\n",
    "    for x in range(100) :\n",
    "        step = random_walk[-1]\n",
    "        dice = np.random.randint(1,7)\n",
    "        if dice <= 2:\n",
    "            step = max(0, step - 1)\n",
    "        elif dice <= 5:\n",
    "            step = step + 1\n",
    "        else:\n",
    "            step = step + np.random.randint(1,7)\n",
    "        random_walk.append(step)\n",
    "    all_walks.append(random_walk)\n",
    "\n",
    "# Convert all_walks to Numpy array: np_aw\n",
    "np_aw = np.array(all_walks)\n",
    "\n",
    "# Plot np_aw and show\n",
    "plt.plot(np_aw)\n",
    "plt.show()\n",
    "\n",
    "# Clear the figure\n",
    "plt.clf()\n",
    "\n",
    "# Transpose np_aw: np_aw_t\n",
    "np_aw_t = np.transpose(np_aw)\n",
    "\n",
    "# Plot np_aw_t and show\n",
    "plt.plot(np_aw_t)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're a bit clumsy and you have a 0.1% chance of falling down. That calls for another random number generation. Basically, you can generate a random float between 0 and 1. If this value is less than or equal to 0.001, you should reset step to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "all_walks = []\n",
    "\n",
    "# Simulate random walk 250 times\n",
    "for i in range(250) :\n",
    "    random_walk = [0]\n",
    "    for x in range(100) :\n",
    "        step = random_walk[-1]\n",
    "        dice = np.random.randint(1,7)\n",
    "        if dice <= 2:\n",
    "            step = max(0, step - 1)\n",
    "        elif dice <= 5:\n",
    "            step = step + 1\n",
    "        else:\n",
    "            step = step + np.random.randint(1,7)\n",
    "\n",
    "        # Implement clumsiness\n",
    "        if np.random.rand(0,1) <= 0.001 :\n",
    "            step = 0\n",
    "\n",
    "        random_walk.append(step)\n",
    "    all_walks.append(random_walk)\n",
    "\n",
    "# Create and plot np_aw_t\n",
    "np_aw_t = np.transpose(np.array(all_walks))\n",
    "plt.plot(np_aw_t)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "all_walks = []\n",
    "\n",
    "# Simulate random walk 500 times\n",
    "for i in range(500) :\n",
    "    random_walk = [0]\n",
    "    for x in range(100) :\n",
    "        step = random_walk[-1]\n",
    "        dice = np.random.randint(1,7)\n",
    "        if dice <= 2:\n",
    "            step = max(0, step - 1)\n",
    "        elif dice <= 5:\n",
    "            step = step + 1\n",
    "        else:\n",
    "            step = step + np.random.randint(1,7)\n",
    "        if np.random.rand() <= 0.001 :\n",
    "            step = 0\n",
    "        random_walk.append(step)\n",
    "    all_walks.append(random_walk)\n",
    "\n",
    "# Create and plot np_aw_t\n",
    "np_aw_t = np.transpose(np.array(all_walks))\n",
    "\n",
    "# Select last row from np_aw_t: ends\n",
    "ends = np_aw_t[-1]\n",
    "\n",
    "\n",
    "# Plot histogram of ends, display plot\n",
    "plt.hist(ends)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Functions\n",
    "<p>\n",
    "* Function bodies need to be indented by a consistent number of spaces and the choice of 4 is common.\n",
    "* The part of the header that specifies the function name and parameter(s), is known as the signature of the function. \n",
    "* Returning values is generally more desirable than printing them out, *return*\n",
    "</p>\n",
    "##### Functions with multiple parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define shout with parameters word1 and word2\n",
    "def shout(word1,word2):\n",
    "    \"\"\"Concatenate strings with three exclamation marks\"\"\"\n",
    "    # Concatenate word1 with '!!!': shout1\n",
    "    \n",
    "    shout1 = word1 + \"!!!\"\n",
    "    # Concatenate word2 with '!!!': shout2\n",
    "    shout2 = word2 + \"!!!\"\n",
    "    \n",
    "    # Concatenate shout1 with shout2: new_shout\n",
    "    new_shout = shout1 + shout2\n",
    "\n",
    "    # Return new_shout\n",
    "    return new_shout\n",
    "\n",
    "# Pass 'congratulations' and 'you' to shout(): yell\n",
    "yell = shout('congratulations','you') \n",
    "\n",
    "# Print yell\n",
    "print(yell)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return multiple values from a function using tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define shout_all with parameters word1 and word2\n",
    "def shout_all(word1,word2):\n",
    "    \n",
    "    # Concatenate word1 with '!!!': shout1\n",
    "    shout1 = word1 + \"!!!\"\n",
    "    \n",
    "    # Concatenate word2 with '!!!': shout2\n",
    "    shout2 = word2 + \"!!!\"\n",
    "    \n",
    "    \n",
    "    # Construct a tuple with shout1 and shout2: shout_words\n",
    "    shout_words = (shout1,shout2)\n",
    "\n",
    "    # Return shout_words\n",
    "    return shout_words\n",
    "\n",
    "# Pass 'congratulations' and 'you' to shout_all(): yell1, yell2\n",
    "yell1, yell2 = shout_all('congratulations', 'you')\n",
    "\n",
    "# Print yell1 and yell2\n",
    "print(yell1)\n",
    "print(yell2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ex:\n",
    "The dataset contains Twitter data and you will iterate over entries in a column to build a dictionary in which the keys are the names of languages and the values are the number of tweets in the given language. The file tweets.csv is available in your current directory.\n",
    "\n",
    "Import the pandas package with the alias pd.\n",
    "Import the file 'tweets.csv' using the pandas function read_csv(). Assign the resulting DataFrame to df.\n",
    "Complete the for loop by iterating over col, the 'lang' column in the DataFrame df.\n",
    "Complete the bodies of the if-else statements in the for loop: if the key is in the dictionary langs_count, add 1 to its current value, else add the key to langs_count and set its value to 1. Use the loop variable entry in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import Twitter data as DataFrame: df\n",
    "df = pd.read_csv(\"tweets.csv\")\n",
    "\n",
    "# Initialize an empty dictionary: langs_count\n",
    "langs_count = {}\n",
    "\n",
    "# Extract column from DataFrame: col\n",
    "col = df['lang']\n",
    "\n",
    "# Iterate over lang column in DataFrame\n",
    "for entry in col:\n",
    "\n",
    "    # If the language is in langs_count, add 1\n",
    "    if entry in langs_count.keys():\n",
    "        langs_count[entry] = langs_count[entry] + 1\n",
    "    # Else add the language to langs_count, set the value to 1\n",
    "    else:\n",
    "        langs_count[entry] = 1\n",
    "\n",
    "# Print the populated dictionary\n",
    "print(langs_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function count_entries(), which has two parameters. The first parameter is df for the DataFrame and the second is col_name for the column name.\n",
    "Complete the bodies of the if-else statements in the for loop: if the key is in the dictionary langs_count, add 1 to its current value, else add the key to langs_count and set its value to 1. Use the loop variable entry in your code.\n",
    "Return the langs_count dictionary from inside the count_entries() function.\n",
    "Call the count_entries() function by passing to it tweets_df and the name of the column, 'lang'. Assign the result of the call to the variable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df,col_name):\n",
    "    \"\"\"Return a dictionary with counts of \n",
    "    occurrences as value for each key.\"\"\"\n",
    "\n",
    "    # Initialize an empty dictionary: langs_count\n",
    "    langs_count = {}\n",
    "    \n",
    "    # Extract column from DataFrame: col\n",
    "    col = df[col_name]\n",
    "    \n",
    "    # Iterate over lang column in DataFrame\n",
    "    for entry in col:\n",
    "\n",
    "        # If the language is in langs_count, add 1\n",
    "        if entry in langs_count.keys():\n",
    "            langs_count[entry] = langs_count[entry]+1\n",
    "        # Else add the language to langs_count, set the value to 1\n",
    "        else:\n",
    "            langs_count[entry] =  1\n",
    "\n",
    "    # Return the langs_count dictionary\n",
    "    return langs_count\n",
    "\n",
    "# Call count_entries(): result\n",
    "result = count_entries(tweets_df,\"lang\")\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keyword *global* within a function to alter the value of a variable defined in the global scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a string: team\n",
    "team = \"teen titans\"\n",
    "\n",
    "# Define change_team()\n",
    "def change_team():\n",
    "    \"\"\"Change the value of the global variable team.\"\"\"\n",
    "\n",
    "    # Use team in global scope\n",
    "    global team\n",
    "\n",
    "    # Change the value of team in global: team\n",
    "    team = \"justice league\"\n",
    "# Print team\n",
    "print(team)\n",
    "\n",
    "# Call change_team()\n",
    "change_team()\n",
    "\n",
    "# Print team\n",
    "print(team)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's built-in scope---a built-in module called builtins, to query builtins, you'll need to *import builtins*.\n",
    "After executing *import builtins* in the IPython Shell, execute *dir(builtins)* to print a list of all the names in the module builtins.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested Functions\n",
    "\n",
    "The nested or inner function remembers the state of its enclosing scope when called. Thus, anything defined locally in the enclosing scope is available to the inner function even when the outer function has finished execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a!!!', 'b!!!', 'c!!!')\n"
     ]
    }
   ],
   "source": [
    "# Define three_shouts\n",
    "def three_shouts(word1, word2, word3):\n",
    "    \"\"\"Returns a tuple of strings\n",
    "    concatenated with '!!!'.\"\"\"\n",
    "\n",
    "    # Define inner\n",
    "    def inner(word):\n",
    "        \"\"\"Returns a string concatenated with '!!!'.\"\"\"\n",
    "        return word + '!!!'\n",
    "\n",
    "    # Return a tuple of strings\n",
    "    return (inner(word1), inner(word2), inner(word3))\n",
    "\n",
    "# Call three_shouts() and print\n",
    "print(three_shouts('a', 'b', 'c'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellohello hellohellohello\n"
     ]
    }
   ],
   "source": [
    "# Define echo\n",
    "def echo(n):\n",
    "    \"\"\"Return the inner_echo function.\"\"\"\n",
    "\n",
    "    # Define inner_echo\n",
    "    def inner_echo(word1):\n",
    "        \"\"\"Concatenate n copies of word1.\"\"\"\n",
    "        echo_word = word1 * n\n",
    "        return echo_word\n",
    "\n",
    "    # Return inner_echo\n",
    "    return inner_echo\n",
    "\n",
    "# Call echo: twice\n",
    "twice = echo(2)\n",
    "\n",
    "# Call echo: thrice\n",
    "thrice = echo(3)\n",
    "\n",
    "# Call twice() and thrice() then print\n",
    "print(twice('hello'), thrice('hello'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The keyword nonlocal and nested functions\n",
    "The keyword nonlocal within a nested function to alter the value of a variable defined in the enclosing scope.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellohello\n",
      "hellohello!!!\n"
     ]
    }
   ],
   "source": [
    "# Define echo_shout()\n",
    "def echo_shout(word):\n",
    "    \"\"\"Change the value of a nonlocal variable\"\"\"\n",
    "    \n",
    "    # Concatenate word with itself: echo_word\n",
    "    echo_word = word + word\n",
    "    \n",
    "    \n",
    "    #Print echo_word\n",
    "    print(echo_word)\n",
    "    \n",
    "    # Define inner function shout()\n",
    "    def shout():\n",
    "        \"\"\"Alter a variable in the enclosing scope\"\"\"    \n",
    "        #Use echo_word in nonlocal scope\n",
    "        nonlocal echo_word\n",
    "        \n",
    "        #Change echo_word to echo_word concatenated with '!!!'\n",
    "        echo_word = echo_word + \"!!!\"\n",
    "    \n",
    "    # Call function shout()\n",
    "    shout()\n",
    "    \n",
    "    #Print echo_word\n",
    "    print(echo_word)\n",
    "\n",
    "#Call function echo_shout() with argument 'hello'    \n",
    "echo_shout(\"hello\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions with variable-length arguments (*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "luke\n",
      "lukeleiahanobidarth\n"
     ]
    }
   ],
   "source": [
    "# Define gibberish\n",
    "def gibberish(*args):\n",
    "    \"\"\"Concatenate strings in *args together.\"\"\"\n",
    "\n",
    "    # Initialize an empty string: hodgepodge\n",
    "    hodgepodge = \"\"\n",
    "\n",
    "    # Concatenate the strings in args\n",
    "    for word in args:\n",
    "        hodgepodge += word\n",
    "\n",
    "    # Return hodgepodge\n",
    "    return hodgepodge\n",
    "\n",
    "# Call gibberish() with one string: one_word\n",
    "one_word = gibberish(\"luke\")\n",
    "\n",
    "# Call gibberish() with five strings: many_words\n",
    "many_words = gibberish(\"luke\", \"leia\", \"han\", \"obi\", \"darth\")\n",
    "\n",
    "# Print one_word and many_words\n",
    "print(one_word)\n",
    "print(many_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions with variable-length keyword arguments (**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEGIN: REPORT\n",
      "\n",
      "name: luke\n",
      "affiliation: jedi\n",
      "status: missing\n",
      "\n",
      "END REPORT\n",
      "\n",
      "BEGIN: REPORT\n",
      "\n",
      "name: anakin\n",
      "affiliation: sith lord\n",
      "status: deceased\n",
      "\n",
      "END REPORT\n"
     ]
    }
   ],
   "source": [
    "# Define report_status\n",
    "def report_status(**kwargs):\n",
    "    \"\"\"Print out the status of a movie character.\"\"\"\n",
    "\n",
    "    print(\"\\nBEGIN: REPORT\\n\")\n",
    "\n",
    "    # Iterate over the key-value pairs of kwargs\n",
    "    for keys, values in kwargs.items():\n",
    "        # Print out the keys and values, separated by a colon ':'\n",
    "        print(keys + \": \" + values)\n",
    "\n",
    "    print(\"\\nEND REPORT\")\n",
    "\n",
    "# First call to report_status()\n",
    "report_status(name=\"luke\", affiliation=\"jedi\",status=\"missing\")\n",
    "\n",
    "# Second call to report_status()\n",
    "report_status(name=\"anakin\", affiliation=\"sith lord\", status=\"deceased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will generalize the Twitter language analysis that you did in the previous chapter. You will do that by including a default argument that takes a column name.\n",
    "Complete the function header by supplying the parameter for a DataFrame df and the parameter col_name with a default value of 'lang' for the DataFrame column name.\n",
    "Call count_entries() by passing the tweets_df DataFrame and the column name 'lang'. Assign the result to result1. Note that since 'lang' is the default value of the col_name parameter, you don't have to specify it here.\n",
    "Call count_entries() by passing the tweets_df DataFrame and the column name 'source'. Assign the result to result2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df, col_name=\"lang\"):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "\n",
    "    # Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "\n",
    "    # Extract column from DataFrame: col\n",
    "    col = df[col_name]\n",
    "    \n",
    "    # Iterate over the column in DataFrame\n",
    "    for entry in col:\n",
    "\n",
    "        # If entry is in cols_count, add 1\n",
    "        if entry in cols_count.keys():\n",
    "            cols_count[entry] += 1\n",
    "\n",
    "        # Else add the entry to cols_count, set the value to 1\n",
    "        else:\n",
    "            cols_count[entry] = 1\n",
    "\n",
    "    # Return the cols_count dictionary\n",
    "    return cols_count\n",
    "\n",
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df)\n",
    "\n",
    "# Call count_entries(): result2\n",
    "result2 = count_entries(tweets_df,col_name='source')\n",
    "\n",
    "# Print result1 and result2\n",
    "print(result1)\n",
    "print(result2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the function header by supplying the parameter for the dataframe df and the flexible argument *args.\n",
    "Complete the for loop within the function definition so that the loop occurs over the tuple args.\n",
    "Call count_entries() by passing the tweets_df DataFrame and the column name 'lang'. Assign the result to result1.\n",
    "Call count_entries() by passing the tweets_df DataFrame and the column names 'lang' and 'source'. Assign the result to result2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df, *args):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    #Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "    \n",
    "    # Iterate over column names in args\n",
    "    for col_name in args:\n",
    "    \n",
    "        # Extract column from DataFrame: col\n",
    "        col = df[col_name]\n",
    "    \n",
    "        # Iterate over the column in DataFrame\n",
    "        for entry in col:\n",
    "    \n",
    "            # If entry is in cols_count, add 1\n",
    "            if entry in cols_count.keys():\n",
    "                cols_count[entry] += 1\n",
    "    \n",
    "            # Else add the entry to cols_count, set the value to 1\n",
    "            else:\n",
    "                cols_count[entry] = 1\n",
    "\n",
    "    # Return the cols_count dictionary\n",
    "    return cols_count\n",
    "\n",
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df, 'lang')\n",
    "\n",
    "# Call count_entries(): result2\n",
    "result2 = count_entries(tweets_df, 'lang', 'source')\n",
    "\n",
    "# Print result1 and result2\n",
    "print(result1)\n",
    "print(result2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda function\n",
    "                      \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def echo_word(word1, echo):\n",
    "    \"\"\"Concatenate echo copies of word1.\"\"\"\n",
    "    words = word1 * echo\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "echo_word = (lambda word1, echo: word1 * echo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map() applies a function over an object, such as a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of strings: spells\n",
    "spells = [\"protego\", \"accio\", \"expecto patronum\", \"legilimens\"]\n",
    "\n",
    "# Use map() to apply a lambda function over spells: shout_spells\n",
    "shout_spells = map(lambda item: item + \"!!!\",spells)\n",
    "\n",
    "# Convert shout_spells to a list: shout_spells_list\n",
    "shout_spells_list = list(shout_spells)\n",
    "\n",
    "# Convert shout_spells into a list and print it\n",
    "print(shout_spells_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function filter() offers a way to filter out elements from a list that don't satisfy certain criteria.\n",
    "\n",
    "The reduce() function is useful for performing some computation on a list and, unlike map() and filter(), returns a single value as a result. To use reduce(), you must import it from the functools module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# Use filter() to apply a lambda function over fellowship: result\n",
    "result = filter(lambda member: len(member) > 6 , fellowship)\n",
    "\n",
    "# Convert result to a list: result_list\n",
    "result_list = list(result)\n",
    "\n",
    "# Convert result into a list and print it\n",
    "print(result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import reduce from functools\n",
    "from functools import reduce \n",
    "\n",
    "# Create a list of strings: stark\n",
    "stark = ['robb', 'sansa', 'arya', 'eddard', 'jon']\n",
    "\n",
    "# Use reduce() to apply a lambda function over stark: result\n",
    "result = reduce(lambda item1,item2:item1+item2,stark)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error-handling\n",
    "\n",
    "try-except block\n",
    "\n",
    "Initialize the variables echo_word and shout_words to empty strings.\n",
    "Add the keywords try and except in the appropriate locations for the exception handling block.\n",
    "Use the * operator to concatenate echo copies of word1. Assign the result to echo_word.\n",
    "Concatenate the string '!!!' to echo_word. Assign the result to shout_words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define shout_echo\n",
    "def shout_echo(word1, echo=1):\n",
    "    \"\"\"Concatenate echo copies of word1 and three\n",
    "    exclamation marks at the end of the string.\"\"\"\n",
    "\n",
    "    # Initialize empty strings: echo_word, shout_words\n",
    "    echo_word=\"\"\n",
    "    shout_words=\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    # Add exception handling with try-except\n",
    "    try:\n",
    "        # Concatenate echo copies of word1 using *: echo_word\n",
    "        echo_word = word1*echo\n",
    "\n",
    "        # Concatenate '!!!' to echo_word: shout_words\n",
    "        shout_words = echo_word + \"!!!\"\n",
    "    except:\n",
    "        # Print error message\n",
    "        print(\"word1 must be a string and echo must be an integer.\")\n",
    "\n",
    "    # Return shout_words\n",
    "    return shout_words\n",
    "\n",
    "# Call shout_echo\n",
    "shout_echo(\"particle\", echo=\"accelerator\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to raise an error is by using *raise*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define shout_echo\n",
    "def shout_echo(word1, echo=1):\n",
    "    \"\"\"Concatenate echo copies of word1 and three\n",
    "    exclamation marks at the end of the string.\"\"\"\n",
    "\n",
    "    # Raise an error with raise\n",
    "    if echo < 0:\n",
    "        raise ValueError('echo must be greater than 0')\n",
    "\n",
    "    # Concatenate echo copies of word1 using *: echo_word\n",
    "    echo_word = word1 * echo\n",
    "\n",
    "    # Concatenate '!!!' to echo_word: shout_word\n",
    "    shout_word = echo_word + '!!!'\n",
    "\n",
    "    # Return shout_word\n",
    "    return shout_word\n",
    "\n",
    "# Call shout_echo\n",
    "shout_echo(\"particle\", echo=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ex.\n",
    "try-except block to allow your function to provide a helpful message when the user calls your count_entries() function but provides a column name that isn't in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df, col_name='lang'):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "\n",
    "    # Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "\n",
    "    # Add try block\n",
    "    try:\n",
    "        # Extract column from DataFrame: col\n",
    "        col = df[col_name]\n",
    "        \n",
    "        # Iterate over the column in dataframe\n",
    "        for entry in col:\n",
    "    \n",
    "            # If entry is in cols_count, add 1\n",
    "            if entry in cols_count.keys():\n",
    "                cols_count[entry] += 1\n",
    "            # Else add the entry to cols_count, set the value to 1\n",
    "            else:\n",
    "                cols_count[entry] = 1\n",
    "    \n",
    "        # Return the cols_count dictionary\n",
    "        return cols_count\n",
    "\n",
    "    # Add except block\n",
    "    except:\n",
    "        print('The DataFrame does not have a ' + col_name + ' column.')\n",
    "\n",
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df, 'lang')\n",
    "\n",
    "# Print result1\n",
    "print(result1)\n",
    "\n",
    "# Call count_entries(): result2\n",
    "result2 = count_entries(tweets_df, 'lang1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### raise a ValueError in the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df, col_name='lang'):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    # Raise a ValueError if col_name is NOT in DataFrame\n",
    "    if col_name not in df.columns:\n",
    "        raise ValueError ('The DataFrame does not have a ' + col_name + ' column.')\n",
    "\n",
    "    # Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "    \n",
    "    # Extract column from DataFrame: col\n",
    "    col = df[col_name]\n",
    "    \n",
    "    # Iterate over the column in DataFrame\n",
    "    for entry in col:\n",
    "\n",
    "        # If entry is in cols_count, add 1\n",
    "        if entry in cols_count.keys():\n",
    "            cols_count[entry] += 1\n",
    "            # Else add the entry to cols_count, set the value to 1\n",
    "        else:\n",
    "            cols_count[entry] = 1\n",
    "        \n",
    "        # Return the cols_count dictionary\n",
    "    return cols_count\n",
    "\n",
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df,\"lang\")\n",
    "\n",
    "# Print result1\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterable is an object that can return an iterator, while an iterator is an object that keeps state and produces the next value when you call next() on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of strings: flash\n",
    "flash = ['jay garrick', 'barry allen', 'wally west', 'bart allen']\n",
    "\n",
    "# Print each list item in flash using a for loop\n",
    "for person in flash:\n",
    "    print(person)\n",
    "    \n",
    "\n",
    "\n",
    "# Create an iterator for flash: superspeed\n",
    "superspeed = iter(flash)\n",
    "\n",
    "# Print each item from the iterator\n",
    "print(next(superspeed))\n",
    "print(next(superspeed))\n",
    "print(next(superspeed))\n",
    "print(next(superspeed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* range() function\n",
    "                  for i in range(5):\n",
    "                       print(i)\n",
    "* There are also functions that take iterators as arguments. For example, the list() and sum() functions return a list and the sum of elements, respectively.\n",
    "\n",
    "* enumerate() returns an enumerate object that produces a sequence of tuples, and each of the tuples is an index-value pair.\n",
    "\n",
    "* zip(),  takes any number of iterables and returns a zip object that is an iterator of tuples. If you wanted to print the values of a zip object, you can convert it into a list and then print it. Printing just a zip object will not return the values unless you unpack it first. In this exercise, you will explore this for yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list comprehension: squares\n",
    "squares = [i**2 for i in range(0,10)]\n",
    "print (squares)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested list comprehensions\n",
    "\n",
    "To create the list of lists, you simply have to supply the list comprehension as the output expression of the overall list comprehension:\n",
    "\n",
    "[[output expression] for iterator variable in iterable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a 5 x 5 matrix using a list of lists: matrix\n",
    "matrix = [[col for col in range(5)] for row in range(5)]\n",
    "\n",
    "# Print the matrix\n",
    "for row in matrix:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# Create list comprehension: new_fellowship\n",
    "new_fellowship = [member if len(member)>= 7 else \"\" for member in fellowship ]\n",
    "\n",
    "# Print the new list\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dict comprehensions\n",
    "You will create a dictionary using the comprehension syntax for this exercise. In this case, the comprehension is called a dict comprehension.\n",
    "\n",
    "The main difference between a list comprehension and a dict comprehension is the use of curly braces {} instead of []. Additionally, members of the dictionary are created using a colon :, as in <key> : <value>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# Create dict comprehension: new_fellowship\n",
    "new_fellowship = {member:len(member) for member in fellowship}\n",
    "\n",
    "# Print the new list\n",
    "print(new_fellowship)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The difference between list comprehensions and generators\n",
    "<p>  # List of strings\n",
    "    fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "    # List comprehension\n",
    "    fellow1 = [member for member in fellowship if len(member) >= 7]\n",
    "\n",
    "    # Generator expression\n",
    "    fellow2 = (member for member in fellowship if len(member) >= 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator expressions\n",
    "\n",
    "\n",
    "Generator functions are functions that, like generator expressions, yield a series of values, instead of returning a single value. A generator function is defined as you do a regular function, but whenever it generates a value, it uses the keyword yield instead of return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create generator object: result\n",
    "result = (num for num in range(31))\n",
    "\n",
    "# Print the first 5 values\n",
    "print(next(result))\n",
    "print(next(result))\n",
    "print(next(result))\n",
    "print(next(result))\n",
    "print(next(result))\n",
    "\n",
    "# Print the rest of the values\n",
    "for value in result:\n",
    "    print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of strings\n",
    "lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']\n",
    "\n",
    "# Define generator function get_lengths\n",
    "def get_lengths(input_list):\n",
    "    \"\"\"Generator function that yields the\n",
    "    length of the strings in input_list.\"\"\"\n",
    "\n",
    "    # Yield the length of a string\n",
    "    for person in input_list:\n",
    "        yield len(person)\n",
    "\n",
    "# Print the values generated by get_lengths()\n",
    "for value in get_lengths(lannister):\n",
    "    print(value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Import data into Python\n",
    "\n",
    "to use the IPython magic command ! ls to explore your current working directory. \n",
    "\n",
    "You can also do this natively in Python using the library os, which consists of miscellaneous operating system interfaces.\n",
    "\n",
    "The first line of the following code imports the library os, the second line stores the name of the current directory in a string called wd and the third outputs the contents of the directory in a list to the shell.\n",
    "\n",
    "import os\n",
    "wd = os.getcwd()\n",
    "os.listdir(wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing entire text files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open a file: file\n",
    "file = open(\"moby_dick.txt\",mode='r')\n",
    "\n",
    "# Print it\n",
    "print(file.read())\n",
    "\n",
    "# Check whether file is closed\n",
    "print(file.closed)\n",
    "\n",
    "# Close file\n",
    "file.close()\n",
    "\n",
    "# Check whether file is closed\n",
    "\n",
    "print(file.closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing text files line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read & print the first 3 lines\n",
    "with open('moby_dick.txt') as file:\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using NumPy to import flat files\n",
    "(Flat files consist of multiple tables with structured relationships between the tables.)\n",
    "\n",
    "* the numpy function *loadtxt()* and see just how easy it can be:\n",
    "1. The first argument will be the filename.\n",
    "2. The second will be the delimiter which, in this case, is a comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import package\n",
    "import numpy as np\n",
    "\n",
    "# Assign filename to variable: file\n",
    "file = 'digits.csv'\n",
    "\n",
    "# Load file as array: digits\n",
    "digits = np.loadtxt(file, delimiter=',')\n",
    "\n",
    "# Print datatype of digits\n",
    "print(type(digits))\n",
    "\n",
    "# Select and reshape a row\n",
    "im = digits[21, 1:]\n",
    "im_sq = np.reshape(im, (28, 28))\n",
    "\n",
    "# Plot reshaped data (matplotlib.pyplot already loaded as plt)\n",
    "plt.imshow(im_sq, cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Customizing your NumPy import\n",
    "\n",
    "* to import particular columns\n",
    "* There are a number of arguments that np.loadtxt() takes that you'll find useful: delimiter changes the delimiter that loadtxt() is expecting, for example, you can use ',' and '\\t' for comma-delimited and tab-delimited respectively; skiprows allows you to specify how many rows (not indices) you wish to skip; usecols takes a list of the indices of the columns you wish to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Assign the filename: file\n",
    "file = 'digits_header.txt'\n",
    "\n",
    "# Load the data: data\n",
    "data = np.loadtxt(\"digits_header.txt\", delimiter='\\t', skiprows=1, usecols=[0,2])\n",
    "\n",
    "# Print data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file seaslug.txt has a text header, consisting of strings is tab-delimited.\n",
    "These data consists of percentage of sea slug larvae that had metamorphosed in a given time period. Read more here.\n",
    "\n",
    "Due to the header, if you tried to import it as-is using np.loadtxt(), Python would throw you a ValueError and tell you that it could not convert string to float. There are two ways to deal with this: firstly, you can set the data type argument dtype equal to str (for string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign filename: file\n",
    "file = 'seaslug.txt'\n",
    "\n",
    "# Import file: data\n",
    "data = np.loadtxt(file, delimiter='\\t', dtype=str)\n",
    "\n",
    "# Print the first element of data\n",
    "print(data[0])\n",
    "\n",
    "# Import data as floats and skip the first row: data_float\n",
    "data_float = np.loadtxt(file, delimiter=\"\\t\", dtype=float, skiprows=1)\n",
    "\n",
    "# Print the 10th element of data_float\n",
    "print(data_float[9])\n",
    "\n",
    "# Plot a scatterplot of the data\n",
    "plt.scatter(data_float[:, 0], data_float[:, 1])\n",
    "plt.xlabel('time (min.)')\n",
    "plt.ylabel('percentage of larvae')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of the time you will need to import datasets which have different datatypes in different columns; one column may contain strings and another floats, for example. The function np.loadtxt() will freak at this. There is another function, np.genfromtxt(), which can handle such structures. If we pass dtype=None to it, it will figure out what types each column should be.\n",
    "\n",
    "ex: data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None\n",
    "\n",
    "\n",
    "There is also another function np.recfromcsv() that behaves similarly to np.genfromtxt(), except that its default dtype is None. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using pandas to import flat files as DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Assign the filename: file\n",
    "file = 'titanic.csv'\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# View the head of the DataFrame\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign the filename: file\n",
    "file = 'digits.csv'\n",
    "\n",
    "# Read the first 5 rows of the file into a DataFrame: data\n",
    "data = pd.read_csv(file, nrows=5, header=None)\n",
    "\n",
    "# Build a numpy array from the DataFrame: data_array\n",
    "data_array = np.array(data.values)\n",
    "\n",
    "# Print the datatype of data_array to the shell\n",
    "print(type(data_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'titanic_corrupt.txt'\n",
    "\n",
    "# Import file: data\n",
    "data = pd.read_csv(file, sep=\"\\t\", comment='#', na_values='Nothing')\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "# Plot 'Age' variable in a histogram\n",
    "pd.DataFrame.hist(data[['Age']])\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading a pickled file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pickle package\n",
    "import pickle\n",
    "\n",
    "# Open pickle file and load data: d\n",
    "with open('data.pkl', \"rb\") as file:\n",
    "    d = pickle.load(file)\n",
    "\n",
    "# Print d\n",
    "print(d)\n",
    "\n",
    "# Print datatype of d\n",
    "print(type(d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing sheets in Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign spreadsheet filename: file\n",
    "file = 'battledeath.xlsx'\n",
    "\n",
    "# Load spreadsheet: xl\n",
    "xl = pd.ExcelFile(file)\n",
    "\n",
    "# Print sheet names\n",
    "print(xl.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load a sheet into a DataFrame by name: df1\n",
    "df1 = xl.parse('2004')\n",
    "\n",
    "# Print the head of the DataFrame df1\n",
    "print(df1.head())\n",
    "\n",
    "# Load a sheet into a DataFrame by index: df2\n",
    "df2 = xl.parse(0)\n",
    "\n",
    "# Print the head of the DataFrame df2\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customizing your spreadsheet import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse the first sheet and rename the columns: df1\n",
    "df1 = xl.parse(0, skiprows=[0], names=['Country','AAM due to War (2002)'])\n",
    "\n",
    "# Print the head of the DataFrame df1\n",
    "print(df1.head())\n",
    "\n",
    "# Parse the first column of the second sheet and rename the column: df2\n",
    "df2 = xl.parse(1, parse_cols=[0], skiprows=[0], names=['Country'])\n",
    "\n",
    "# Print the head of the DataFrame df2\n",
    "print(df2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing SAS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import sas7bdat package\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "# Save file to a DataFrame: df_sas\n",
    "with SAS7BDAT('sales.sas7bdat') as file:\n",
    "   df_sas= file.to_data_frame()\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df_sas.head())\n",
    "\n",
    "# Plot histogram of DataFrame features (pandas and pyplot already imported)\n",
    "pd.DataFrame.hist(df_sas[['P']])\n",
    "plt.ylabel('count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Stata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load Stata file into a pandas DataFrame: df\n",
    "df= pd.read_stata('disarea.dta')\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "print(df.head())\n",
    "\n",
    "# Plot histogram of one column of the DataFrame\n",
    "pd.DataFrame.hist(df[['disa10']])\n",
    "plt.xlabel('Extent of disease')\n",
    "plt.ylabel('Number of coutries')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using h5py to import HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'LIGO_data.hdf5'\n",
    "\n",
    "# Load file: data\n",
    "data = h5py.File(file, \"r\")\n",
    "\n",
    "# Print the datatype of the loaded file\n",
    "print(type(data))\n",
    "\n",
    "# Print the keys of the file\n",
    "for key in data.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing MATLAB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'albeck_gene_expression.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-14d389ff1fea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load MATLAB file: mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmat\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'albeck_gene_expression.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print the datatype type of mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[1;32m    134\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mMR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[0;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m        \u001b[0mtype\u001b[0m \u001b[0mdetected\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mbyte_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mmjv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'albeck_gene_expression.mat'"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import scipy.io\n",
    "\n",
    "# Load MATLAB file: mat\n",
    "mat= scipy.io.loadmat('albeck_gene_expression.mat')\n",
    "\n",
    "# Print the datatype type of mat\n",
    "print(type(mat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a database engine\n",
    "\n",
    "To create an engine to connect to the SQLite database.\n",
    "ex: create an engine to connect to the SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary module\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# Open engine connection: con\n",
    "con= engine.connect()\n",
    "\n",
    "# Perform query: rs\n",
    "rs = con.execute(\"SELECT * FROM Album\")\n",
    "\n",
    "# Save results of the query to DataFrame: df\n",
    "df = pd.DataFrame(rs.fetchall())\n",
    "\n",
    "# Close connection\n",
    "con.close()\n",
    "\n",
    "# Print head of DataFrame df\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open engine in context manager\n",
    "# Perform query and save results to DataFrame: df\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT LastName, Title FROM Employee\")\n",
    "    df = pd.DataFrame(rs.fetchmany(size=3))\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "# Print the length of the DataFrame df\n",
    "print(len(df))\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing flat files from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import package\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url,'winequality-red.csv', )\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performing HTTP requests in Python using urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen,Request\n",
    "\n",
    "# Specify the url\n",
    "url = \"http://www.datacamp.com/teach/documentation\"\n",
    "\n",
    "# This packages the request: request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Print the datatype of response\n",
    "print(type(response))\n",
    "\n",
    "# Be polite and close the response!\n",
    "response.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use the BeautifulSoup package to parse, prettify and extract information from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = \"https://www.python.org/~guido/\"\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Get the title of Guido's webpage: guido_title\n",
    "guido_title = soup.title\n",
    "\n",
    "# Print the title of Guido's webpage to the shell\n",
    "print(guido_title)\n",
    "\n",
    "# Get Guido's text: guido_text\n",
    "guido_text = soup.get_text()\n",
    "\n",
    "# Print Guido's text to the shell\n",
    "print(guido_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and exploring a JSON\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load JSON: json_data\n",
    "with open(\"a_movie.json\") as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "# Print each key-value pair in json_data\n",
    "for k in json_data.keys():\n",
    "    print(k + ': ', json_data[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and viewing your data\n",
    "\n",
    "* .describe() method to calculate summary statistics of your data.\n",
    "* .value_counts() method, which returns the frequency counts for each unique value in a column(also has an optional parameter called dropna which is True by default,if you have missing data in a column, it will not give a frequency count of them. You want to set the dropna column to False so if there are missing values in a column, it will give you the frequency counts)\n",
    "* .plot() method allows you to create a plot of each column of a DataFrame. The kind parameter allows you to specify the type of plot \n",
    "* pd.melt() Melting data is the process of turning columns of your data into rows of data. \n",
    "* .pivot_table() method - Pivoting data is the opposite of melting it.(use pivot tables to deal with duplicate values by providing an aggregation function through the aggfunc parameter)\n",
    "* an advantage of pandas' vectorized string slicing by using the str attribute of columns of type object.\n",
    "* Python's built-in string method called .split(). By default, this method will split a string into parts separated by a space.\n",
    "* by accessing the str attribute of the column and using the .get() method to retrieve the index, depending on the part you want.\n",
    "* glob module to find all csv files in the workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv('dob_job_application_filings_subset.csv')\n",
    "# Print the head of df\n",
    "print(df.head())\n",
    "\n",
    "# Print the tail of df\n",
    "print(df.tail())\n",
    "\n",
    "# Print the shape of df\n",
    "print(df.shape)\n",
    "\n",
    "# Print the columns of df\n",
    "print(df.columns)\n",
    "\n",
    "# Print the head and tail of df_subset\n",
    "print(df_subset.head())\n",
    "print(df_subset.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate uber1, uber2, and uber3: row_concat\n",
    "row_concat = pd.concat([uber1, uber2, uber3])\n",
    "# Print the shape of row_concat\n",
    "print(row_concat.shape)\n",
    "\n",
    "# Print the head of row_concat\n",
    "print(row_concat.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging data allows you to combine disparate datasets into a single dataset to do more complex analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge the DataFrames: o2o\n",
    "o2o = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# Print o2o\n",
    "print(o2o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge the DataFrames: m2o\n",
    "m2o = pd.merge(left=site,right=visited,left_on='name',right_on='site')\n",
    "\n",
    "# Print m2o\n",
    "print(m2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " Merge site and visited: m2m\n",
    "m2m = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# Merge m2m and survey: m2m\n",
    "m2m = pd.merge(left=m2m, right=survey, left_on='ident', right_on='taken')\n",
    "\n",
    "# Print the first 20 lines of m2m\n",
    "print(m2m.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the pd.to_numeric() function to convert a column into a numeric data type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert 'total_bill' to a numeric dtype\n",
    "tips['total_bill'] = pd.to_numeric(tips['total_bill'], errors='coerce')\n",
    "\n",
    "# Convert 'tip' to a numeric dtype\n",
    "tips['tip'] = pd.to_numeric(tips['tip'], errors='coerce')\n",
    "\n",
    "# Print the info of tips\n",
    "print(tips.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the pattern using re.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the regular expression module\n",
    "import re\n",
    "\n",
    "# Compile the pattern: prog\n",
    "prog = re.compile('\\d{3}-\\d{3}-\\d{4}')\n",
    "\n",
    "# See if the pattern matches\n",
    "result = prog.match('123-456-7890')\n",
    "print(bool(result))\n",
    "\n",
    "# See if the pattern matches\n",
    "result = prog.match('1123-456-7890')\n",
    "print(bool(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting numerical values from strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the regular expression module\n",
    "import re\n",
    "\n",
    "# Find the numeric values: matches\n",
    "matches = re.findall('\\d+', 'the recipe calls for 10 strawberries and 1 banana')\n",
    "\n",
    "# Print the matches\n",
    "print(matches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* .apply() method to apply a function across entire rows or columns of DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define recode_sex()\n",
    "def recode_sex(sex_value):\n",
    "\n",
    "    # Return 1 if sex_value is 'Male'\n",
    "    if sex_value == 'Male':\n",
    "        return 1\n",
    "    \n",
    "    # Return 0 if sex_value is 'Female'    \n",
    "    elif sex_value == 'Female':\n",
    "        return 0\n",
    "    \n",
    "    # Return np.nan    \n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to the sex column\n",
    "tips['sex_recode'] = tips.sex.apply(recode_sex)\n",
    "\n",
    "# Print the first five rows of tips\n",
    "print(tips.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the new DataFrame: tracks\n",
    "tracks = billboard[['year', 'artist', 'track','time']]\n",
    "\n",
    "# Print info of tracks\n",
    "print(tracks.info())\n",
    "\n",
    "# Drop the duplicates: tracks_no_duplicates\n",
    "tracks_no_duplicates = tracks.drop_duplicates()\n",
    "\n",
    "# Print info of tracks\n",
    "print(tracks_no_duplicates.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the mean of the Ozone column: oz_mean\n",
    "oz_mean = airquality.Ozone.mean()\n",
    "\n",
    "# Replace all the missing values in the Ozone column with the mean\n",
    "airquality['Ozone'] = airquality.Ozone.fillna(oz_mean)\n",
    "\n",
    "# Print the info of airquality\n",
    "print(airquality.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the .all() method together with the .notnull() DataFrame method to check for missing values in a column. The .all() method returns True if all values are True. When used on a DataFrame, it returns a Series of Booleans - one for each column in the DataFrame. \n",
    "Using it on a DataFrame to chain another and all() method so that you return only one True or False value. When using these within an assert statement, nothing will be returned if the assert statement is true: This is how you can confirm that the data you are checking are valid.\n",
    "\n",
    "You can use pd.notnull(df) as an alternative to df.notnull()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assert that there are no missing values\n",
    "assert pd.notnull(ebola).all().all()\n",
    "\n",
    "# Assert that all values are >= 0\n",
    "assert (ebola >= 0).all().all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Time series in pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read in the same data file using three different approaches:\n",
    "df1 = pd.read_csv(filename)\n",
    "df2 = pd.read_csv(filename, parse_dates=['Date'])\n",
    "df3 = pd.read_csv(filename, index_col='Date', parse_dates=True)\n",
    "\n",
    "\n",
    "The pandas Index is a powerful way to handle time series data, so it is valuable to know how to build one yourself. Pandas provides the pd.to_datetime() function\n",
    "\n",
    "Partial string indexing and slicing\n",
    "\n",
    "ex.Extract data from ts0 for a single hour - the hour from 9pm to 10pm on 2010-10-11. Assign it to ts1.\n",
    "Extract data from ts0 for a single day - July 4th, 2010 - and assign it to ts2.\n",
    "Extract data from ts0 for the second half of December 2010 - 12/15/2010 to 12/31/2010. Assign it to ts3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the hour from 9pm to 10pm on '2010-10-11': ts1\n",
    "ts1 = ts0.loc['2010-10-11 21:00:00']\n",
    "\n",
    "# Extract '2010-07-04' from ts0: ts2\n",
    "ts2 = ts0.loc['2010-07-04']\n",
    "\n",
    "# Extract data from '2010-12-15' to '2010-12-31': ts3\n",
    "ts3 = ts0.loc['2010-12-15':'2010-12-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reindexing is useful in preparation for adding or otherwise combining two time series data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reindex without fill method: ts3\n",
    "ts3 =ts2 .reindex(ts1.index)\n",
    "\n",
    "# Reindex with fill method, using forward fill: ts4\n",
    "ts4 = ts2 .reindex(ts1.index,method=\"ffill\")\n",
    "\n",
    "# Combine ts1 + ts2: sum12\n",
    "sum12 = ts1 + ts2\n",
    "\n",
    "# Combine ts1 + ts3: sum13\n",
    "sum13 = ts1 + ts3\n",
    "\n",
    "# Combine ts1 + ts4: sum14\n",
    "sum14 = ts1 + ts4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When downsampling or upsampling, the syntax is similar, but the methods called are different. Both use the concept of 'method chaining' - df.method1().method2().method3() - to direct the output from one method call to the input of the next, and so on, as a sequence of operations, one feeding into the next.\n",
    "\n",
    "\n",
    "### Rolling mean and frequency\n",
    "\n",
    "To use the .rolling() method, you must always use method chaining, first calling .rolling() and then chaining an aggregation method after it. For example, with a Series hourly_data, hourly_data.rolling(window=24).mean() would compute new values for each hourly point, based on a 24-hour window stretching out behind each point. The frequency of the output data is the same: it is still hourly. Such an operation is useful for smoothing time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract data from 2010-Aug-01 to 2010-Aug-15: unsmoothed\n",
    "unsmoothed = df['Temperature'][\"2010-08-01\":\"2010-08-15\"]\n",
    "\n",
    "# Apply a rolling mean with a 24 hour window: smoothed\n",
    "smoothed =unsmoothed.rolling(window=24).mean()\n",
    "\n",
    "# Create a new DataFrame with columns smoothed and unsmoothed: august\n",
    "august = pd.DataFrame({'smoothed':smoothed, 'unsmoothed':unsmoothed })\n",
    "\n",
    "# Plot both smoothed and unsmoothed data using august.plot().\n",
    "august.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
